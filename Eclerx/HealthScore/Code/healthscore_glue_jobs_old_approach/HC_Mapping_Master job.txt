import pandas as pd
import numpy as np
from awsglue.transforms import *
from awsglue.utils import getResolvedOptions
from pyspark.context import SparkContext
from awsglue.context import GlueContext
from awsglue.job import Job
from pyspark.sql import functions as F
from datetime import datetime
from pyspark.sql import SparkSession
from pyspark.sql.window import Window
from pyspark.sql.types import StringType
sc = SparkContext.getOrCreate()
glueContext = GlueContext(sc)
spark = glueContext.spark_session
job = Job(glueContext)


input_path = 's3://cci-dig-aicoe-data-sb/processed/da/HealthScore/Testing_HS/'
df = spark.read.option("header", "true").csv(input_path)
df.show()
df = df.withColumn("original_index", F.monotonically_increasing_id())
date_columns = df.columns[3:]
for col in date_columns:
    df = df.withColumn(col, df[col].cast("int"))

df.show()
placeholder_columns = ['New_Metrics_Name']  
for col in placeholder_columns:
    df = df.withColumn(col, F.lit(" ").cast(StringType()))

pandas_df= df.toPandas()
main_metric = ['DR_SmartHelp - Landing Page', 'DR_SmartHelp - Started', 'DR_SmartHelp - P&P', 'DR_SmartHelp - Billing & Account Support', 'DR_SmartHelp - Internet Support', 'DR_SmartHelp - TV Support', 'DR_SmartHelp - Homelife Support', 'DR_SmartHelp - Agent Chat']
remaining_metrics = set(pandas_df['Metrics']) - set(main_metric)
pandas_df['Sub Metric'] = pd.NA
pandas_df.loc[pandas_df['Metrics'].isin(remaining_metrics), 'Sub Metric'] = pandas_df['Metrics']
print(pandas_df.columns)
unique_df = df.select("Metrics", "Operating System Type").distinct()
unique_df = unique_df.filter(F.col("Metrics").isNotNull() & F.col("Operating System Type").isNotNull())
unique_df = unique_df.join(df.select("Metrics", "Operating System Type", "original_index"), 
                            on=["Metrics", "Operating System Type"], how="inner")
window_spec = Window.orderBy("original_index")
unique_df = unique_df.withColumn("id", F.row_number().over(window_spec))
df_relevant = df.select("Metrics", "Operating System Type", "original_index", *placeholder_columns)
id_placeholder_df = unique_df.select("Metrics", "Operating System Type", "id") \
    .join(df_relevant, on=["Metrics", "Operating System Type"], how="left")
display_name_mapping = {

'DR_SmartHelp - Landing Page' : 'Devices Page Visits',
'DR_SmartHelp - Started' : 'Started Troubleshooting (Solution Center)',
'DR_SmartHelp - Result' : 'Saw a Result',
'DR_SmartHelp Result - Unknown' : '1st common reason (Unknown)',
'DR_SmartHelp Result - Disconnected' : '2nd common reason (Disconnected)',
'DR_SmartHelp Result - Incomplete Install' : '3rd common reason (Incomplete Install)',
'DR_SmartHelp - Reboot Flow Started' : 'Did a Device Reboot',
'DR_SmartHelp - P&P' : 'Started Proactive and Preventive (P&P)',
"DR_Smarthelp P&P - Let's troubleshoot together" : 'Started P&P troubleshooting',
'DR_Smarthelp P&P - Reset Complete' : 'Reset Complete',
"DR_Smarthelp P&P - Let's schedule a technician visit" : 'Schedule Tech',
'DR_Smarthelp P&P - Connect with a support agent' : 'Connect with Agent',
'DR_Smarthelp P&P - Interacted with Chat Agent' : 'Interacted with Chat_1',
'DR_SmartHelp - Billing & Account Support' : 'Clicked Billing & Account Support',
'DR_SmartHelp - Internet Support' : 'Clicked Internet Support',
'DR_SmartHelp - TV Support' : 'Clicked TV Support',
'DR_SmartHelp - Homelife Support' : 'Clicked Homelife Support',
'DR_SmartHelp - Agent Chat' : 'Interacted with Chat',
    }
broadcast_mapping = spark.sparkContext.broadcast(display_name_mapping)
def get_display_name(metric):
    return broadcast_mapping.value.get(metric, metric)

get_display_name_udf = F.udf(get_display_name)

df = df.withColumn("display_name", get_display_name_udf(F.col("Metrics")))

final_output_df = id_placeholder_df.join(
    df.select("Metrics", "Operating System Type", "display_name"),
    on=["Metrics", "Operating System Type"],
    how="left"
)

final_output_df = final_output_df.withColumn("Sub Metric", F.when(~F.col("Metrics").isin(main_metric), F.col("Metrics")).otherwise(F.lit(None)))

final_output_df = final_output_df.withColumn(
    "subdisplay", 
    F.when(F.col("Metrics") == F.col("Sub Metric"), F.col("display_name")).otherwise(F.lit(None))
)
final_output_df = final_output_df.withColumn("Feature", F.lit("Smarthelp"))

final_output_df = final_output_df.select(
    "id", "Metrics", "Sub Metric", "Operating System Type", "display_name",
    "Feature", "subdisplay", *placeholder_columns
)
final_output_df = final_output_df.orderBy("id")

final_output_df.show()
now = datetime.now()
current_date = now.date()

# Add create_dt column
final_output_df = final_output_df.withColumn("create_dt", F.lit(current_date))
final_output_df.show()
final_output_df = final_output_df.withColumn("Sub Metric", F.col("Sub Metric").cast(StringType()))
final_output_df = final_output_df.withColumn("subdisplay", F.col("subdisplay").cast(StringType()))
output_path = 's3://cci-dig-aicoe-data-sb/processed/da/HealthScore/HC_Mapping_Master/' 
final_output_df.coalesce(1).write.mode("overwrite").option("header", "true").csv(output_path)
final_output_df.show()
final_output_df.printSchema()
job.commit()
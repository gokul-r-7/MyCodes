import pandas as pd
import numpy as np
from awsglue.transforms import *
from awsglue.utils import getResolvedOptions
from pyspark.context import SparkContext
from awsglue.context import GlueContext
from awsglue.job import Job
from pyspark.sql import functions as F
from datetime import datetime
from pyspark.sql import Window

sc = SparkContext.getOrCreate()
glueContext = GlueContext(sc)
spark = glueContext.spark_session
job = Job(glueContext)

input_path = 's3://cci-dig-aicoe-data-sb/processed/da/HealthScore/Testing_HS/'
df = spark.read.option("header", "true").csv(input_path)
df.show()
date_columns = df.columns[3:]
for col in date_columns:
    df = df.withColumn(col, df[col].cast("int"))
id_mapping_path = 's3://cci-dig-aicoe-data-sb/processed/da/HealthScore/HC_Mapping_Master/'  
id_placeholder_df = spark.read.option("header", "true").csv(id_mapping_path)
id_placeholder_df = id_placeholder_df.withColumnRenamed("id", "id_mapping")
df = df.join(
    id_placeholder_df.select("Metrics", "Operating System Type", "id_mapping"),
    on=["Metrics", "Operating System Type"],
    how="left"
)
df.show()
pandas_df = df.toPandas()
now = datetime.now()
current_date = now.date()
pandas_df['create_dt'] = current_date
date_columns = pandas_df.columns[3:-2].tolist()
id_vars = ['id_mapping', 'create_dt']
df_melted = pandas_df.melt(id_vars=id_vars, value_vars=date_columns, var_name='Date', value_name='Value')

df_melted = df_melted[(df_melted['id_mapping'].notna()) & (df_melted['id_mapping'] != 0)]

df_melted['id_mapping'] = df_melted['id_mapping'].fillna(0).astype(int)
df_melted['Value'] = pd.to_numeric(df_melted['Value'], errors='coerce').fillna(0).astype(int)

df_melted['Date'] = pd.to_datetime(df_melted['Date'], errors='coerce').dt.date
df_melted['create_dt'] = pd.to_datetime(df_melted['create_dt'], errors='coerce').dt.date

spark_df = spark.createDataFrame(df_melted)
spark_df = spark_df.withColumn("Date", F.to_date(F.col("Date")))
spark_df.show()
spark_df.dtypes
output_path = 's3://cci-dig-aicoe-data-sb/processed/da/HealthScore/HC_Source_Data_Actual/' 
spark_df.coalesce(1).write.mode("overwrite").option("header", "true").csv(output_path)
spark_df.show()
job.commit()
import pandas as pd
import numpy as np
from awsglue.transforms import *
from awsglue.utils import getResolvedOptions
from pyspark.context import SparkContext
from awsglue.context import GlueContext
from awsglue.job import Job
from pyspark.sql import functions as F
from datetime import datetime
from pyspark.sql import Window
from pyspark.sql import SparkSession
from pyspark.sql.functions import to_date, col
from pyspark.sql.types import IntegerType
from datetime import datetime, timedelta



sc = SparkContext.getOrCreate()
glueContext = GlueContext(sc)
spark = glueContext.spark_session
job = Job(glueContext)
spark = SparkSession.builder.appName("DateConversion").getOrCreate()
spark = SparkSession.builder.appName("Replace Nulls").getOrCreate()

input_path = 's3://cci-dig-aicoe-data-sb/processed/da/HealthScore/Testing_HS/'
df = spark.read.option("header", "true").csv(input_path)
df.show()
date_columns = df.columns[3:]
for col in date_columns:
    df = df.withColumn(col, df[col].cast("int"))
id_map = 's3://cci-dig-aicoe-data-sb/processed/da/HealthScore/HC_Mapping_Master/'
id_placeholder_df = spark.read.option("header", "true").csv(id_map)
df_new = df.join(
    id_placeholder_df.select("Metrics", "Operating System Type", "id"),
    on=["Metrics", "Operating System Type"],
    how="left"
)
pandas_df = df_new.toPandas()

date_columns = pandas_df.columns[3:-1].tolist()
id_vars = ['Metrics','Operating System Type','Metric+OS']
df_melted = pandas_df.melt(id_vars=id_vars, value_vars=date_columns, var_name='Date', value_name='Value')
df_pivot = df_melted.pivot_table(index=['Date', 'Operating System Type'], columns='Metrics', values='Value', aggfunc='first').reset_index()
column_mapping = {
    'DR_SmartHelp - Agent Chat' : 'Interacted with Chat',
    'DR_SmartHelp - Billing & Account Support' : 'Clicked Billing & Account Support',
    'DR_SmartHelp - Homelife Support' : 'Clicked Homelife Support',
    'DR_SmartHelp - Internet Support' : 'Clicked Internet Support',
    'DR_SmartHelp - Landing Page' : 'Devices Page Visits',
    'DR_SmartHelp - P&P' : 'Started Proactive and Preventive (P&P)',
    'DR_SmartHelp - Reboot Flow Started' : 'Did a Device Reboot',
    'DR_SmartHelp - Result' : 'Saw a Result',
    'DR_SmartHelp - Started' : 'Started Troubleshooting (Solution Center)',
    'DR_SmartHelp - TV Support' : 'Clicked TV Support',
    'DR_SmartHelp Result - Disconnected' : '2nd common reason (Disconnected)',
    'DR_SmartHelp Result - Incomplete Install' : '3rd common reason (Incomplete Install)',
    'DR_SmartHelp Result - Unknown' : '1st common reason (Unknown)',
    'DR_Smarthelp P&P - Connect with a support agent' : 'Connect with Agent',
    'DR_Smarthelp P&P - Interacted with Chat Agent' : 'Interacted with Chat_1',
    "DR_Smarthelp P&P - Let's schedule a technician visit" : 'Schedule Tech',
    "DR_Smarthelp P&P - Let's troubleshoot together" : 'Started P&P troubleshooting',
    'DR_Smarthelp P&P - Reset Complete' : 'Reset Complete'
}
df_pivot.rename(columns = column_mapping, inplace = True)
 
df_pivot['1st common reason (Unknown) %'] = (df_pivot['1st common reason (Unknown)'] / df_pivot['Saw a Result'] * 100).round(3)
df_pivot['2nd common reason (Disconnected) %'] = (df_pivot['2nd common reason (Disconnected)'] / df_pivot['Saw a Result'] * 100).round(3)
df_pivot['3rd common reason (Incomplete Install) %'] = (df_pivot['3rd common reason (Incomplete Install)'] / df_pivot['Saw a Result'] * 100).round(3)
df_pivot['Clicked Billing & Account Support %'] = (df_pivot['Clicked Billing & Account Support'] / df_pivot['Devices Page Visits'] * 100).round(3)
df_pivot['Clicked Homelife Support %'] = (df_pivot['Clicked Homelife Support'] / df_pivot['Devices Page Visits'] * 100).round(3)
df_pivot['Clicked Internet Support %'] = (df_pivot['Clicked Internet Support'] / df_pivot['Devices Page Visits'] * 100).round(3)
df_pivot['Clicked TV Support %'] = (df_pivot['Clicked TV Support'] / df_pivot['Devices Page Visits'] * 100).round(3)
df_pivot['Connect with Agent %'] = (df_pivot['Connect with Agent'] / df_pivot['Started Proactive and Preventive (P&P)'] * 100).round(3)
df_pivot['Did a Device Reboot %'] = (df_pivot['Did a Device Reboot'] / df_pivot['Devices Page Visits'] * 100).round(3)
df_pivot['Interacted with Chat %'] = (df_pivot['Interacted with Chat'] / df_pivot['Started Proactive and Preventive (P&P)'] * 100).round(3)
df_pivot['Interacted with Chat_1 %'] = (df_pivot['Interacted with Chat_1'] / df_pivot['Devices Page Visits'] * 100).round(3)
df_pivot['Reset Complete %'] = (df_pivot['Reset Complete'] / df_pivot['Started Proactive and Preventive (P&P)'] * 100).round(3)
df_pivot['Saw a Result %'] = (df_pivot['Saw a Result'] / df_pivot['Started Troubleshooting (Solution Center)'] * 100).round(3)
df_pivot['Schedule Tech %'] = (df_pivot['Schedule Tech'] / df_pivot['Started Proactive and Preventive (P&P)'] * 100).round(3)
df_pivot['Started P&P troubleshooting %'] = (df_pivot['Started P&P troubleshooting'] / df_pivot['Started Proactive and Preventive (P&P)'] * 100).round(3)
df_pivot['Started Proactive and Preventive (P&P) %'] = (df_pivot['Started Proactive and Preventive (P&P)'] / df_pivot['Devices Page Visits'] * 100).round(3)
df_pivot['Started Troubleshooting (Solution Center) %'] = (df_pivot['Started Troubleshooting (Solution Center)'] / df_pivot['Devices Page Visits'] * 100).round(3)
 
 
melted_df = df_pivot.melt(id_vars=['Date', 'Operating System Type'], var_name='Metric', value_name='Value')
 
# Pivot the DataFrame
pivoted_df = melted_df.pivot_table(
    index=['Operating System Type', 'Metric'],
    columns='Date',
    values='Value',
    aggfunc='first'
).reset_index()
 
# Rename the columns to reflect the date values directly
pivoted_df.columns.name = None  # Remove the index name
pivoted_df.columns = ['Operating System Type', 'Metric'] + list(pivoted_df.columns[2:])  
 
 
# Function to calculate the sum for a given metric and operating system
def calculate_sum(df, os_type, metric):
    return df[(df['Operating System Type'] == os_type) & (df['Metric'] == metric)].iloc[:, 2:].sum()
 
# Calculate sums for both operating systems for "Devices Page Visits"
date_columns = pivoted_df.columns[2:]
both_row = {'Operating System Type': 'Both', 'Metric': 'Devices Page Visits'}
 
both_row.update({date: calculate_sum(pivoted_df, 'Google Android', 'Devices Page Visits')[date] +
                 calculate_sum(pivoted_df, 'Apple iOS', 'Devices Page Visits')[date] for date in date_columns})
 
# Create and concatenate new row DataFrame
combined_df = pd.concat([pivoted_df, pd.DataFrame([both_row])], ignore_index=True)
 
# Function to calculate metrics for "Both"
def calculate_metric_both(df, metric_name):
    both_row = {'Operating System Type': 'Both', 'Metric': metric_name}
    for date in date_columns:
        android_numerator = (calculate_sum(df, 'Google Android', metric_name)[date] *
                             calculate_sum(df, 'Google Android', 'Devices Page Visits')[date])
       
        apple_numerator = (calculate_sum(df, 'Apple iOS', metric_name)[date] *
                           calculate_sum(df, 'Apple iOS', 'Devices Page Visits')[date])
       
        numerator = android_numerator + apple_numerator
        devices_visits_both = df.loc[
            (df['Operating System Type'] == 'Both') &
            (df['Metric'] == 'Devices Page Visits'), date
        ].values[0]
       
        both_row[date] = numerator / devices_visits_both if devices_visits_both > 0 else 0
 
    return pd.DataFrame([both_row])
 
# Calculate new metrics for various percentages
combined_df = pd.concat([combined_df, calculate_metric_both(combined_df, "Started Troubleshooting (Solution Center) %")], ignore_index=True)
combined_df = pd.concat([combined_df, calculate_metric_both(combined_df, "Interacted with Chat_1 %")], ignore_index=True)
combined_df = pd.concat([combined_df, calculate_metric_both(combined_df, "Clicked Homelife Support %")], ignore_index=True)
combined_df = pd.concat([combined_df, calculate_metric_both(combined_df, "Clicked TV Support %")], ignore_index=True)
combined_df = pd.concat([combined_df, calculate_metric_both(combined_df, "Did a Device Reboot %")], ignore_index=True)
combined_df = pd.concat([combined_df, calculate_metric_both(combined_df, "Started Proactive and Preventive (P&P) %")], ignore_index=True)
combined_df = pd.concat([combined_df, calculate_metric_both(combined_df, "Clicked Internet Support %")], ignore_index=True)
combined_df = pd.concat([combined_df, calculate_metric_both(combined_df, "Clicked Billing & Account Support %")], ignore_index=True)
 
# Select only the relevant date columns
date_columns = combined_df.columns[2:]
 
# Initialize a list to hold the rows for all metrics
both_rows = []
 
# Calculate the new metric for "Both" for "Saw a Result"
saw_result_row = {
    'Operating System Type': 'Both',
    'Metric': "Saw a Result %"
}
 
for date in date_columns:
    # Calculate the numerator
    android_numerator = combined_df[
        (combined_df['Operating System Type'] == 'Google Android') &
        (combined_df['Metric'] == 'Saw a Result')
    ][date].sum()  # Use .sum() to handle multiple rows
   
    apple_numerator = combined_df[
        (combined_df['Operating System Type'] == 'Apple iOS') &
        (combined_df['Metric'] == 'Saw a Result')
    ][date].sum()  # Use .sum() to handle multiple rows
   
    numerator = android_numerator + apple_numerator
   
    # Calculate the denominator
    started_troubleshooting_both = combined_df.loc[
        (combined_df['Operating System Type'] == 'Google Android') &
        (combined_df['Metric'] == 'Started Troubleshooting (Solution Center)'),
        date
    ].sum() + combined_df.loc[
        (combined_df['Operating System Type'] == 'Apple iOS') &
        (combined_df['Metric'] == 'Started Troubleshooting (Solution Center)'),
        date
    ].sum()
   
    # Calculate the final value for "Saw a Result" in percentage
    saw_result_row[date] = (numerator / started_troubleshooting_both * 100) if started_troubleshooting_both > 0 else 0
 
# Append the "Saw a Result" row
both_rows.append(saw_result_row)
 
# Calculate the new metric for "1st common reason (Unknown)"
unknown_reason_row = {
    'Operating System Type': 'Both',
    'Metric': "1st common reason (Unknown) %"
}
 
for date in date_columns:
    # Calculate the numerator
    android_numerator = combined_df[
        (combined_df['Operating System Type'] == 'Google Android') &
        (combined_df['Metric'] == '1st common reason (Unknown)')
    ][date].sum()  # Use .sum() to handle multiple rows
   
    apple_numerator = combined_df[
        (combined_df['Operating System Type'] == 'Apple iOS') &
        (combined_df['Metric'] == '1st common reason (Unknown)')
    ][date].sum()  # Use .sum() to handle multiple rows
   
    numerator = android_numerator + apple_numerator
   
    # Calculate the denominator
    saw_result_both = combined_df.loc[
        (combined_df['Operating System Type'] == 'Google Android') &
        (combined_df['Metric'] == 'Saw a Result'),
        date
    ].sum() + combined_df.loc[
        (combined_df['Operating System Type'] == 'Apple iOS') &
        (combined_df['Metric'] == 'Saw a Result'),
        date
    ].sum()
   
    # Calculate the final value for "1st common reason (Unknown)" in percentage
    unknown_reason_row[date] = (numerator / saw_result_both * 100) if saw_result_both > 0 else 0
 
# Append the "1st common reason (Unknown)" row
both_rows.append(unknown_reason_row)
 
# Calculate the new metric for "2nd common reason (Disconnected)"
disconnected_row = {
    'Operating System Type': 'Both',
    'Metric': "2nd common reason (Disconnected) %"
}
 
for date in date_columns:
    # Calculate the numerator
    android_numerator = combined_df[
        (combined_df['Operating System Type'] == 'Google Android') &
        (combined_df['Metric'] == '2nd common reason (Disconnected)')
    ][date].sum()  # Use .sum() to handle multiple rows
   
    apple_numerator = combined_df[
        (combined_df['Operating System Type'] == 'Apple iOS') &
        (combined_df['Metric'] == '2nd common reason (Disconnected)')
    ][date].sum()  # Use .sum() to handle multiple rows
   
    numerator = android_numerator + apple_numerator
   
    # Calculate the denominator
    disconnected_both = combined_df.loc[
        (combined_df['Operating System Type'] == 'Google Android') &
        (combined_df['Metric'] == 'Saw a Result'),
        date
    ].sum() + combined_df.loc[
        (combined_df['Operating System Type'] == 'Apple iOS') &
        (combined_df['Metric'] == 'Saw a Result'),
        date
    ].sum()
   
    # Calculate the final value for "2nd common reason (Disconnected)" in percentage
    disconnected_row[date] = (numerator / disconnected_both * 100) if disconnected_both > 0 else 0
 
# Append the "2nd common reason (Disconnected)" row
both_rows.append(disconnected_row)
 
# Calculate the new metric for "3rd common reason (Incomplete Install)"
incomplete_install_row = {
    'Operating System Type': 'Both',
    'Metric': "3rd common reason (Incomplete Install) %"
}
 
for date in date_columns:
    # Calculate the numerator
    android_numerator = combined_df[
        (combined_df['Operating System Type'] == 'Google Android') &
        (combined_df['Metric'] == '3rd common reason (Incomplete Install)')
    ][date].sum()  # Use .sum() to handle multiple rows
   
    apple_numerator = combined_df[
        (combined_df['Operating System Type'] == 'Apple iOS') &
        (combined_df['Metric'] == '3rd common reason (Incomplete Install)')
    ][date].sum()  # Use .sum() to handle multiple rows
   
    numerator = android_numerator + apple_numerator
   
    # Calculate the denominator
    incomplete_install_both = combined_df.loc[
        (combined_df['Operating System Type'] == 'Google Android') &
        (combined_df['Metric'] == 'Saw a Result'),
        date
    ].sum() + combined_df.loc[
        (combined_df['Operating System Type'] == 'Apple iOS') &
        (combined_df['Metric'] == 'Saw a Result'),
        date
    ].sum()
   
    # Calculate the final value for "3rd common reason (Incomplete Install)" in percentage
    incomplete_install_row[date] = (numerator / incomplete_install_both * 100) if incomplete_install_both > 0 else 0
 
# Append the "3rd common reason (Incomplete Install)" row
both_rows.append(incomplete_install_row)
 
# Create a DataFrame for the new rows
both_df = pd.DataFrame(both_rows)
 
# Concatenate the new rows to the original combined DataFrame
combined_df = pd.concat([combined_df, both_df], ignore_index=True)
 
#TO BE UESD
 
# Select only the relevant date columns
date_columns = combined_df.columns[2:]
 
# Initialize a list to hold the rows for all metrics
results_rows = []
 
# Define a function to calculate metrics
def calculate_metric(metric_name, numerator_conditions, denominator_conditions):
    metric_row = {
        'Operating System Type': 'Both',
        'Metric': metric_name
    }
   
    for date in date_columns:
        # Calculate the numerator
        android_numerator = combined_df[
            (combined_df['Operating System Type'] == 'Google Android') &
            (combined_df['Metric'].isin(numerator_conditions))
        ][date].sum()
 
        apple_numerator = combined_df[
            (combined_df['Operating System Type'] == 'Apple iOS') &
            (combined_df['Metric'].isin(numerator_conditions))
        ][date].sum()
 
        numerator = android_numerator + apple_numerator
       
        # Calculate the denominator
        android_denominator = combined_df[
            (combined_df['Operating System Type'] == 'Google Android') &
            (combined_df['Metric'].isin(denominator_conditions))
        ][date].sum()
 
        apple_denominator = combined_df[
            (combined_df['Operating System Type'] == 'Apple iOS') &
            (combined_df['Metric'].isin(denominator_conditions))
        ][date].sum()
 
        denominator = android_denominator + apple_denominator
 
        # Calculate the final value in percentage
        metric_row[date] = (numerator / denominator * 100) if denominator > 0 else 0
   
    return metric_row
 
# Calculate each metric
results_rows.append(calculate_metric(
    "Started P&P troubleshooting %",
    ["Started P&P troubleshooting"],
    ["Started Proactive and Preventive (P&P)"]
))
 
results_rows.append(calculate_metric(
    "Reset Complete %",
    ["Reset Complete"],
    ["Started Proactive and Preventive (P&P)"]
))
 
results_rows.append(calculate_metric(
    "Schedule Tech %",
    ["Schedule Tech"],
    ["Started Proactive and Preventive (P&P)"]
))
 
results_rows.append(calculate_metric(
    "Connect with Agent %",
    ["Connect with Agent"],
    ["Started Proactive and Preventive (P&P)"]
))
 
results_rows.append(calculate_metric(
    "Interacted with Chat %",
    ["Interacted with Chat"],
    ["Started Proactive and Preventive (P&P)"]
))
 
# Create a DataFrame for the new rows
results_df = pd.DataFrame(results_rows)
 
# Concatenate the new rows to the original combined DataFrame
combined_df1 = pd.concat([combined_df, results_df], ignore_index=True)
combined_df1.head()
 
melted_df = pd.melt(combined_df1, id_vars=['Metric', 'Operating System Type'],
                     value_vars=combined_df1.columns[2:],
                     var_name='Date',
                     value_name='Value')
 
 
melteddf_pivot = melted_df.pivot_table(
    index=['Operating System Type', 'Metric'], 
    columns='Date', 
    values='Value', 
    aggfunc='first'
).reset_index()
melteddf_pivot.columns.name = None  # Remove the index name
melteddf_pivot.columns = ['Operating System Type', 'Metric'] + list(melteddf_pivot.columns[2:])

final_melted_df = pd.melt(melteddf_pivot, id_vars=['Operating System Type', 'Metric'],
                           var_name='Date', value_name='Value')

final_melted_df['Date'] = pd.to_datetime(final_melted_df['Date'], errors='coerce')
final_melted_df['Date'] = final_melted_df['Date'].dt.date

percentage_columns = [col for col in final_melted_df['Metric'].unique() if '%' in col]
percentage_columns.append('Devices Page Visits')
filtered_final_df = final_melted_df[final_melted_df['Metric'].isin(percentage_columns)]


filtered_final_df = filtered_final_df.sort_values(by=['Date', 'Operating System Type', 'Metric'])
filtered_final_df['Metric'] = filtered_final_df['Metric'].str.replace('%', '', regex=False)

filtered_final_df['Metric'] = filtered_final_df['Metric'].str.strip()
spark_df = spark.createDataFrame(filtered_final_df)
joined_df = spark_df.join(
    id_placeholder_df,
    (spark_df.Metric == id_placeholder_df.display_name) & (spark_df["Operating System Type"] == id_placeholder_df["Operating System Type"]),
    "left"
)
selected_columns_df = joined_df.select(
    id_placeholder_df["id"],
    spark_df["Metric"],
    spark_df["Operating System Type"],
    spark_df["Value"],
    spark_df["Date"],
    id_placeholder_df["display_name"]
)
pandas_df = selected_columns_df.toPandas()
now = datetime.now()
current_date = now.date()
selected_columns_df = selected_columns_df.withColumn("create_dt", F.lit(current_date))
selected_columns_df.show()
selected_columns_df = selected_columns_df.withColumn("id", selected_columns_df["id"].cast(IntegerType()))
selected_columns_df.dtypes
df_filled = selected_columns_df.fillna({"id": 0})
pandas_df = df_filled.toPandas()
pandas_df['Date'] = pd.to_datetime(pandas_df['Date'], format='%Y-%m-%d')
print(pandas_df)
latest_date = pandas_df['Date'].max() 
print(latest_date)


start_date = latest_date - pd.Timedelta(days=90)
print(start_date)

filtered_df = pandas_df[(pandas_df['Date'] > start_date) & (pandas_df['Date'] < latest_date)]
print(filtered_df)

dates = filtered_df['Date'].unique()
print(dates)
quartiles = melted_df.groupby(['Operating System Type', 'Metric'])['Value'].quantile([0.25, 0.75]).unstack()
quartiles.reset_index(inplace=True)
quartiles.columns.name = None  # Remove the index name
quartiles.columns = ['Operating System Type', 'Metric', '1st Quartile', '3rd Quartile']
quartiles['1st Quartile'] = quartiles['1st Quartile'].round(1)
quartiles['3rd Quartile'] = quartiles['3rd Quartile'].round(1)
# Step 11: Calculate IQR
quartiles['IQR'] = quartiles['3rd Quartile'] - quartiles['1st Quartile']
 
 
# Step 12: Calculate Upper and Lower bounds
# For all metrics except "Devices Page Visits"
quartiles.loc[quartiles['Metric'] != 'Devices Page Visits', 'Upper'] = quartiles['3rd Quartile'] + (0.75 * quartiles['IQR'])
quartiles.loc[quartiles['Metric'] != 'Devices Page Visits', 'Lower'] = quartiles['1st Quartile'] - (0.75 * quartiles['IQR'])
 
# Special case for "Devices Page Visits"
devices_page_visits = quartiles[quartiles['Metric'] == 'Devices Page Visits']
quartiles.loc[quartiles['Metric'] == 'Devices Page Visits', 'Upper'] = devices_page_visits['3rd Quartile'] + (1.25 * devices_page_visits['IQR'])
quartiles.loc[quartiles['Metric'] == 'Devices Page Visits', 'Lower'] = devices_page_visits['1st Quartile'] - (1.25 * devices_page_visits['IQR'])
quartiles['Upper'] = quartiles['Upper'].round(1)
quartiles['Lower'] = quartiles['Lower'].round(1)
df = pd.merge(combined_df1, quartiles, on=['Operating System Type', 'Metric'], how='left')
df.head(100)
date_columns= df.columns[2:]
print(date_columns)
date_columns2= date_columns[:-5]
print(date_columns2)
# Convert the identified date columns to datetime
date_columns_dt = pd.to_datetime(date_columns2, format='%m/%d/%Y')
# Find the latest date column
latest_date_col = date_columns[date_columns_dt.argmax()]
# Create a new column with the latest date's values
df['Yesterday'] = df[latest_date_col]
print(df)
df = df[df['Metric'].str.endswith("%") | (df['Metric'] == "Devices Page Visits") ]
df =df.reset_index(drop=True)
print(df)
all_columns_list = list(df.columns)
dates = [date for date in all_columns_list if '/' in date]
sorted_dates = sorted(dates, key=lambda x: datetime.strptime(x, '%m/%d/%Y'))
last7datecolumns = sorted_dates[-8:-1]
last30datecolumns = sorted_dates[-31:-1]
print(last7datecolumns)
print(last30datecolumns)
last_7days_df = df[last7datecolumns]
last_30days_df = df[last30datecolumns]
device_page_visit_df_7 = last_7days_df[df['Metric']=="Devices Page Visits"]
meandf_7 = device_page_visit_df_7.mean(axis=1)

device_page_visit_df_30 = last_30days_df[df['Metric']=="Devices Page Visits"]
meandf_30 = device_page_visit_df_30.mean(axis=1)

devicepagevisit_df_7 = last_7days_df[df['Metric']=="Devices Page Visits"]
devicepagevisit_df_7 = devicepagevisit_df_7.reset_index(drop=True)

devicepagevisit_df_30 = last_30days_df[df['Metric']=="Devices Page Visits"]
devicepagevisit_df_30 = devicepagevisit_df_30.reset_index(drop=True)
results_7 = []
results_30 = []
all_metrics = list(set(df['Metric']))
all_metrics.remove("Devices Page Visits")
for items in all_metrics:
    newdf_7 = last_7days_df[df['Metric']==items]
    old_index_7 = newdf_7.index 
    newdf_7 = newdf_7.reset_index(drop=True)
    sumproduct_7 = (newdf_7 * devicepagevisit_df_7).sum(axis=1)
    result_7 = sumproduct_7/devicepagevisit_df_7.sum(axis=1)
    result_7.index = old_index_7
    results_7.append(result_7)

results_7.append(meandf_7)
final_result_7 = pd.concat(results_7)
df['Last 7 Days'] = final_result_7
for item in all_metrics:
    newdf_30 = last_30days_df[df['Metric']==item]
    old_index_30 = newdf_30.index 
    newdf_30 = newdf_30.reset_index(drop=True)
    sumproduct_30 = (newdf_30 * devicepagevisit_df_30).sum(axis=1)
    result_30 = sumproduct_30/devicepagevisit_df_30.sum(axis=1)
    result_30.index = old_index_30
    results_30.append(result_30)

results_30.append(meandf_30)
final_result_30 = pd.concat(results_30)
df['Last 30 Days'] = final_result_30
df['% Change Last 7 Days'] =  (df['Yesterday']- df['Last 7 Days'])/df['Last 7 Days']
df['% Change Last 7 Days']*=100
df['% Change Last 7 Days'] = df['% Change Last 7 Days'].round(1)
df['% Change Last 30 Days'] =  (df['Yesterday']- df['Last 30 Days'])/df['Last 30 Days']
df['% Change Last 30 Days']*=100
df['% Change Last 30 Days'] = df['% Change Last 30 Days'].round(1)
df['Metric + OS'] = df['Metric']+ ' ' + df['Operating System Type']
all_columns_ls = list(df.columns)
dates = [date for date in all_columns_list if '/' in date]
sorted_dates = sorted(dates, key=lambda x: datetime.strptime(x, '%m/%d/%Y'))
print(sorted_dates)
non_date_columns = [col for col in df.columns if col not in sorted_dates]
print(non_date_columns)
sorted_df = pd.concat([df[non_date_columns], df[sorted_dates]], axis=1)

non_date_columns = [col for col in sorted_df.columns if '/' not in col]  
date_columns = [col for col in sorted_df.columns if '/' in col]
melted_df = pd.melt(sorted_df, id_vars=non_date_columns, value_vars=date_columns,
                    var_name='Date', value_name='Value')
melted_df['Date'] = pd.to_datetime(melted_df['Date'], format='%m/%d/%Y').dt.date

melted_df = melted_df.sort_values(by='Date')

print(melted_df.columns)

melted_df['Metric'] = melted_df['Metric'].str.replace('%', '', regex=False)
print(melted_df.head())
df_id_placeholder_pandas = id_placeholder_df.toPandas()
reverse_column_mapping = {v: k for k, v in column_mapping.items()}

melted_df['Metric'] = melted_df['Metric'].str.strip()

melted_df['Metric'] = melted_df['Metric'].map(reverse_column_mapping).fillna(melted_df['Metric'])

print(melted_df[['Metric', 'Operating System Type', '1st Quartile', 
 '3rd Quartile', 'IQR', 'Upper', 'Lower', 'Yesterday', 'Last 7 Days', 'Last 30 Days',
 '% Change Last 7 Days',
 '% Change Last 30 Days',
 'Date' ,
 'Value']])

spark_df1 = spark.createDataFrame(melted_df)
spark_df1 = spark_df1.drop('Metric + OS', 'Mapped_Metric' )
now = datetime.now()
current_date = now.date()
spark_df1 = spark_df1.withColumn("create_dt", F.lit(current_date))
id_placeholder_df = id_placeholder_df.alias("id_df")
spark_df1 = spark_df1.alias("sprk_df")
final_df = spark_df1.join(
    id_placeholder_df.select(
        "id_df.id", "id_df.Metrics", "id_df.Operating System Type"
    ),  # Select only the necessary columns from the id_placeholder_df
    (spark_df1['Metric'] == id_placeholder_df['Metrics']) & 
    (spark_df1['Operating System Type'] == id_placeholder_df['Operating System Type']),
    how='left'
)
final_df = final_df.select(
    "sprk_df.Metric", "sprk_df.Operating System Type", "sprk_df.1st Quartile", "sprk_df.3rd Quartile", 
    "sprk_df.IQR", "sprk_df.Upper", "sprk_df.Lower", "sprk_df.Yesterday", "sprk_df.Last 7 Days", 
    "sprk_df.Last 30 Days", "sprk_df.% Change Last 7 Days", "sprk_df.% Change Last 30 Days", 
    "sprk_df.Date", "sprk_df.Value", "sprk_df.create_dt", "id_df.id"
)
mask = final_df['id'].isNull() | (final_df['id'] == 0)
unique_combinations = final_df.filter(mask).dropDuplicates(['Metric', 'Operating System Type'])

window_spec = Window.orderBy(F.monotonically_increasing_id()) 

unique_combinations_with_ids = unique_combinations.withColumn("new_id", F.row_number().over(window_spec))

final_df = final_df.join(
    unique_combinations_with_ids.select('Metric', 'Operating System Type', 'new_id'),
    on=['Metric', 'Operating System Type'],
    how='left'
)
final_df = final_df.withColumn('id', F.when(final_df['id'].isNull() | (final_df['id'] == 0), F.col('new_id')).otherwise(final_df['id']))

final_df = final_df.drop('new_id')
final_df = final_df.withColumn("id", F.col("id").cast("int"))

final_df.printSchema()
output_path = 's3://cci-dig-aicoe-data-sb/processed/da/HealthScore/Healthscore_Last7_30/'
final_df.coalesce(1).write.mode("overwrite").option("header", "true").csv(output_path)
final_df.show(100)
job.commit()
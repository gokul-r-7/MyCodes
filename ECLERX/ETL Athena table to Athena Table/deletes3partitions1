import boto3
from datetime import datetime, timedelta
import re

# Initialize S3 client
s3_client = boto3.client('s3')

# Define bucket and folder paths
bucket_name = "gokul_bucket"
folder_paths = ["account_dim/", "profile_dim/"]

# Define the regex pattern to match 'time_key' partitions
time_key_pattern = re.compile(r'time_key=(\d{4}-\d{2}-\d{2})/')

# Define a cutoff date for keeping only the last 13 months
cutoff_date = datetime.now() - timedelta(days=13 * 30)  # Roughly 13 months

def get_partition_dates(prefix):
    """Get all 'time_key' partitions as dates from the given S3 prefix."""
    partition_dates = []
    result = s3_client.list_objects_v2(Bucket=bucket_name, Prefix=prefix)
    if 'Contents' in result:
        for obj in result['Contents']:
            match = time_key_pattern.search(obj['Key'])
            if match:
                date_str = match.group(1)
                date_obj = datetime.strptime(date_str, "%Y-%m-%d")
                partition_dates.append(date_obj)
    return sorted(set(partition_dates))

def delete_old_partitions(prefix):
    """Delete partitions older than 13 months."""
    partition_dates = get_partition_dates(prefix)
    if len(partition_dates) > 13:
        for date in partition_dates[:-13]:  # Keep only the last 13 months
            partition_prefix = f"{prefix}time_key={date.strftime('%Y-%m-%d')}/"
            result = s3_client.list_objects_v2(Bucket=bucket_name, Prefix=partition_prefix)
            if 'Contents' in result:
                for obj in result['Contents']:
                    s3_client.delete_object(Bucket=bucket_name, Key=obj['Key'])
                print(f"Deleted partition: {partition_prefix}")

# Run the deletion check on both folders
for folder in folder_paths:
    delete_old_partitions(folder)